{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F56vFOJNlb5W"
   },
   "source": [
    "# Conenct to Google Drive\n",
    "\n",
    "If the dataset is in your gogle Drive run the following comand, click on the link at the outuput and insert you authorization code. Then, your Dive folder will be Mout in the runtime files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 58446,
     "status": "ok",
     "timestamp": 1623496196333,
     "user": {
      "displayName": "Fernando kelvin da silva soares",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GirZTqoss84BmkxdunrF_M6ylZ77CQlrq30dI3gk_E=s64",
      "userId": "16326058525254127284"
     },
     "user_tz": 180
    },
    "id": "Zo5oSkXpmI8O",
    "outputId": "44ea773a-aa2c-41a3-e1c2-d0366db8d490"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WkRreBf1eDVc"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 2188,
     "status": "ok",
     "timestamp": 1623496202655,
     "user": {
      "displayName": "Fernando kelvin da silva soares",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GirZTqoss84BmkxdunrF_M6ylZ77CQlrq30dI3gk_E=s64",
      "userId": "16326058525254127284"
     },
     "user_tz": 180
    },
    "id": "Ja7sezsmnXph"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "import os\n",
    "from os import listdir, mkdir, path\n",
    "\n",
    "import io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from PIL import Image\n",
    "from collections import namedtuple, OrderedDict\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VrdQHgvNijTi"
   },
   "source": [
    "Auxiliar functions based on the dataset_util.py script  of the Tensorflow Object detection API "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 462,
     "status": "ok",
     "timestamp": 1623496205668,
     "user": {
      "displayName": "Fernando kelvin da silva soares",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GirZTqoss84BmkxdunrF_M6ylZ77CQlrq30dI3gk_E=s64",
      "userId": "16326058525254127284"
     },
     "user_tz": 180
    },
    "id": "mbsPOUpVtYxA"
   },
   "outputs": [],
   "source": [
    "def int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "\n",
    "def int64_list_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n",
    "\n",
    "\n",
    "def bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "\n",
    "def bytes_list_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=value))\n",
    "\n",
    "\n",
    "def float_feature(value):\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "\n",
    "def float_list_feature(value):\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n",
    "  \n",
    "\n",
    "def progress(value, max=100):\n",
    "    return HTML(\"\"\"\n",
    "        <progress\n",
    "            value='{value}'\n",
    "            max='{max}',\n",
    "            style='width: 50%'\n",
    "        >\n",
    "         {value}\n",
    "        </progress>\n",
    "    \"\"\".format(value=value, max=max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "executionInfo": {
     "elapsed": 577,
     "status": "ok",
     "timestamp": 1623499148728,
     "user": {
      "displayName": "Fernando kelvin da silva soares",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GirZTqoss84BmkxdunrF_M6ylZ77CQlrq30dI3gk_E=s64",
      "userId": "16326058525254127284"
     },
     "user_tz": 180
    },
    "id": "Z34cCZYAtKy3"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def create_tf_example(file, images_path, annotations_path, labels_dict):\n",
    "  \n",
    "    car = file.split(\"_\")[0] \n",
    "    if car == \"tesla\":\n",
    "        car_folder = \"model3\"\n",
    "    elif car == \"lexus\":\n",
    "        car_folder = \"gsf\"\n",
    "    else:\n",
    "        car_folder = car\n",
    "\n",
    "    sub_folder = file.split(\"_\")[1] \n",
    "    if sub_folder == 'test':\n",
    "        sub_folder = 'test_with_labels'\n",
    "    image_filename = file.split(\".\")[0] +\".png\"\n",
    "\n",
    "    image_file_path = images_path + \"/{}/{}/grayscale_wholeImage/{}\".format(car_folder,sub_folder,image_filename)\n",
    "\n",
    "    with tf.io.gfile.GFile(image_file_path, 'rb') as fid:\n",
    "        encoded_png = fid.read()\n",
    "    encoded_png_io = io.BytesIO(encoded_png)\n",
    "    image = Image.open(encoded_png_io)\n",
    "\n",
    "    \n",
    "    im = Image.open(image_file_path, 'r').convert('L')\n",
    "    print('Pillow: ', image.mode, image.size)\n",
    "    print('Pillow: ', im.mode, im.size)\n",
    "    print(image)\n",
    "    print(im)\n",
    "        \n",
    "    \n",
    "    img = cv2.imread(image_file_path, cv2.IMREAD_UNCHANGED)\n",
    "    print('OpenCV: ', img.shape)\n",
    "\n",
    "    width, height = image.size\n",
    "\n",
    "    filename = image_filename.encode('utf8')\n",
    "    image_format = b'png'\n",
    "    xmins = []\n",
    "    xmaxs = []\n",
    "    ymins = []\n",
    "    ymaxs = []\n",
    "    classes_text = []\n",
    "    classes = []\n",
    "\n",
    "    bbox_path = annotations_path + \"/{}/{}/boundingBoxes_wholeImage/{}\".format(car_folder,sub_folder,file)\n",
    "    with open(bbox_path) as f:\n",
    "        boxes = f.read().split(\"\\n\")\n",
    "\n",
    "    for box in boxes:\n",
    "        info = box.split(\",\")\n",
    "        if len(info) == 5:\n",
    "            # print(info)\n",
    "            classes.append(int(info[0]))\n",
    "            classes_text.append(labels_dict[info[0]].encode('utf8'))\n",
    "            print(classes)\n",
    "            print(classes_text)\n",
    "            xmin = int(info[1]) / width\n",
    "            ymin = int(info[2]) / height\n",
    "            xmax = int(info[3]) / width\n",
    "            ymax = int(info[4]) / height\n",
    "            if xmin > xmax:\n",
    "                print(\"erro xmin > xmax\")\n",
    "            xmins.append(int(info[1]) / width)\n",
    "            ymins.append(int(info[2]) / height)\n",
    "            xmaxs.append(int(info[3]) / width)\n",
    "            ymaxs.append(int(info[4]) / height)\n",
    "        \n",
    "  \n",
    "    tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'image/height': int64_feature(height),\n",
    "        'image/width': int64_feature(width),\n",
    "        'image/filename': bytes_feature(filename),\n",
    "        'image/source_id': bytes_feature(filename),\n",
    "        'image/encoded': bytes_feature(encoded_png),\n",
    "        'image/format': bytes_feature(image_format),\n",
    "        'image/object/bbox/xmin': float_list_feature(xmins),\n",
    "        'image/object/bbox/xmax': float_list_feature(xmaxs),\n",
    "        'image/object/bbox/ymin': float_list_feature(ymins),\n",
    "        'image/object/bbox/ymax': float_list_feature(ymaxs),\n",
    "        'image/object/class/text': bytes_list_feature(classes_text),\n",
    "        'image/object/class/label': int64_list_feature(classes),\n",
    "    }))\n",
    "    return tf_example\n",
    "\n",
    "\n",
    "def write_tf_record(files, record_path, max_files):\n",
    "    with tf.io.TFRecordWriter(record_path) as writer:\n",
    "        count = 0\n",
    "        number_of_files = len(files)\n",
    "\n",
    "        out_display = display(progress(0, 100), display_id=True)\n",
    "\n",
    "        print(\"Writing: {}\".format(record_name))\n",
    "        for file in files[:max_files]:\n",
    "            example = create_tf_example(file, input_images_path,\n",
    "                                      input_bbox_annotations_path,\n",
    "                                      labels_map_dict)\n",
    "            writer.write(example.SerializeToString())\n",
    "            count += 1\n",
    "            out_display.update(progress(int((count/max_files)*100), 100))\n",
    "        writer.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gV3NgLeHwMe-"
   },
   "source": [
    "Label map definition for the SVIRO classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 1234,
     "status": "ok",
     "timestamp": 1623496236731,
     "user": {
      "displayName": "Fernando kelvin da silva soares",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GirZTqoss84BmkxdunrF_M6ylZ77CQlrq30dI3gk_E=s64",
      "userId": "16326058525254127284"
     },
     "user_tz": 180
    },
    "id": "1gZlH_zRoAmB"
   },
   "outputs": [],
   "source": [
    "labels_map_dict  = {\n",
    "    \"1\" : \"infant_seat\",\n",
    "    \"2\" : \"child_seat\",\n",
    "    \"3\" : \"person\",\n",
    "    \"4\" : \"everyday_object\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tH5vUkQvnMzy"
   },
   "source": [
    "Point the path to the location of the SVIRO dataset folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 401,
     "status": "ok",
     "timestamp": 1623496233971,
     "user": {
      "displayName": "Fernando kelvin da silva soares",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GirZTqoss84BmkxdunrF_M6ylZ77CQlrq30dI3gk_E=s64",
      "userId": "16326058525254127284"
     },
     "user_tz": 180
    },
    "id": "iKq4GCddnDMl"
   },
   "outputs": [],
   "source": [
    "# sviro_dataset_path = \"/content/gdrive/MyDrive/Colab Notebooks/SVIRO_Challenge/dataset\"\n",
    "sviro_dataset_path = \"C:/Users/ferwi/Google Drive/Colab Notebooks/SVIRO_Challenge/dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 639,
     "status": "ok",
     "timestamp": 1623496240639,
     "user": {
      "displayName": "Fernando kelvin da silva soares",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GirZTqoss84BmkxdunrF_M6ylZ77CQlrq30dI3gk_E=s64",
      "userId": "16326058525254127284"
     },
     "user_tz": 180
    },
    "id": "pJcJyidvuiJd"
   },
   "outputs": [],
   "source": [
    "input_images_path = sviro_dataset_path + \"/grayscale\"\n",
    "input_bbox_annotations_path = sviro_dataset_path + \"/boundingBoxes\"\n",
    "output_tf_record_output_path = sviro_dataset_path + \"/tfrecords\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yVd7fIiO8z1M"
   },
   "source": [
    "Listo of the cars folders, according to the SVIRO dataset folder name, that will be used for the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 366,
     "status": "ok",
     "timestamp": 1623496244224,
     "user": {
      "displayName": "Fernando kelvin da silva soares",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GirZTqoss84BmkxdunrF_M6ylZ77CQlrq30dI3gk_E=s64",
      "userId": "16326058525254127284"
     },
     "user_tz": 180
    },
    "id": "_lR27V8j8n4A"
   },
   "outputs": [],
   "source": [
    "cars_for_train = [\"zoe\", \"hilux\", \"model3\"]\n",
    "cars_for_test = [\"zoe\", \"hilux\", \"model3\", \"x5\", \"tiguan\"]\n",
    "\n",
    "training_split = 0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CBQf3rujLSZY"
   },
   "source": [
    "Get the train and test files with the bouding boxes annotations from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3235,
     "status": "ok",
     "timestamp": 1623497284156,
     "user": {
      "displayName": "Fernando kelvin da silva soares",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GirZTqoss84BmkxdunrF_M6ylZ77CQlrq30dI3gk_E=s64",
      "userId": "16326058525254127284"
     },
     "user_tz": 180
    },
    "id": "qmk-GSCakad7",
    "outputId": "69960e1b-9a81-47e4-b7f6-3573599f5b30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting training files from: zoe\n",
      "Getting training files from: hilux\n",
      "Getting training files from: model3\n",
      "Getting test files from: zoe\n",
      "Getting test files from: hilux\n",
      "Getting test files from: model3\n",
      "Getting test files from: x5\n",
      "Getting test files from: tiguan\n",
      "Total files for training: 4500\n",
      "Total files for validation: 1500\n",
      "Total files for testing: 2500\n"
     ]
    }
   ],
   "source": [
    "# get the train files with the bouding boxes annotations from the dataset\n",
    "train_files = [] \n",
    "valid_files = [] \n",
    "\n",
    "random.seed(0)\n",
    "for car in cars_for_train:\n",
    "    print(\"Getting training files from: {}\".format(car))\n",
    "    car_train_dir = input_bbox_annotations_path + \"/{}/train/boundingBoxes_wholeImage\".format(car)\n",
    "    files = [f for f in listdir(car_train_dir) if path.isfile(path.join(car_train_dir, f)) and f.endswith(\".txt\")]\n",
    "    # shuffle the files and split them for concatenate in the test finles and validation files\n",
    "    random.shuffle(files)\n",
    "    split_point = int((len(files)+1)*training_split)\n",
    "    train_files = train_files + files[:split_point] \n",
    "    valid_files = valid_files + files[split_point:] \n",
    "\n",
    "# get the test files with the bouding boxes annotations from the dataset\n",
    "test_files = []\n",
    "for car in cars_for_test:\n",
    "    print(\"Getting test files from: {}\".format(car))\n",
    "    car_test_dir = input_bbox_annotations_path + \"/{}/test_with_labels/boundingBoxes_wholeImage\".format(car)\n",
    "    test_files = test_files + [f for f in listdir(car_test_dir) if path.isfile(path.join(car_test_dir, f)) and f.endswith(\".txt\")]\n",
    "\n",
    "random.shuffle(train_files)\n",
    "random.shuffle(valid_files)\n",
    "random.shuffle(test_files)\n",
    "\n",
    "print(\"Total files for training: {}\".format(len(train_files)))\n",
    "print(\"Total files for validation: {}\".format(len(valid_files)))\n",
    "print(\"Total files for testing: {}\".format(len(test_files)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "bwhuun_0CtK-",
    "outputId": "680cbd18-e630-4eee-e5d0-152d90b54a2f",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <progress\n",
       "            value='100'\n",
       "            max='100',\n",
       "            style='width: 50%'\n",
       "        >\n",
       "         100\n",
       "        </progress>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing: /SVIRO_bla_images.tfrecord\n",
      "Pillow:  RGB (960, 640)\n",
      "Pillow:  L (960, 640)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=960x640 at 0x1C97181ED30>\n",
      "<PIL.Image.Image image mode=L size=960x640 at 0x1C97181EFA0>\n",
      "OpenCV:  (640, 960, 3)\n",
      "[3]\n",
      "[b'person']\n",
      "[3, 3]\n",
      "[b'person', b'person']\n",
      "Pillow:  RGB (960, 640)\n",
      "Pillow:  L (960, 640)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=960x640 at 0x1C97181ECA0>\n",
      "<PIL.Image.Image image mode=L size=960x640 at 0x1C97154ED00>\n",
      "OpenCV:  (640, 960, 3)\n",
      "[3]\n",
      "[b'person']\n",
      "[3, 3]\n",
      "[b'person', b'person']\n",
      "[3, 3, 2]\n",
      "[b'person', b'person', b'child_seat']\n",
      "Pillow:  RGB (960, 640)\n",
      "Pillow:  L (960, 640)\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=960x640 at 0x1C970473C40>\n",
      "<PIL.Image.Image image mode=L size=960x640 at 0x1C9704737F0>\n",
      "OpenCV:  (640, 960, 3)\n",
      "[3]\n",
      "[b'person']\n",
      "[3, 2]\n",
      "[b'person', b'child_seat']\n",
      "[3, 2, 2]\n",
      "[b'person', b'child_seat', b'child_seat']\n"
     ]
    }
   ],
   "source": [
    "record_name = '/SVIRO_bla_images.tfrecord'\n",
    "record_path = output_tf_record_output_path + record_name \n",
    "\n",
    "# write_tf_record(train_files, record_path, max_files=int(len(train_files)))\n",
    "write_tf_record(train_files, record_path, max_files=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 214
    },
    "executionInfo": {
     "elapsed": 3716,
     "status": "error",
     "timestamp": 1623497305114,
     "user": {
      "displayName": "Fernando kelvin da silva soares",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GirZTqoss84BmkxdunrF_M6ylZ77CQlrq30dI3gk_E=s64",
      "userId": "16326058525254127284"
     },
     "user_tz": 180
    },
    "id": "R6fTLGng6vzb",
    "outputId": "54534bfa-6d17-4900-a9a1-e53579355ff4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <progress\n",
       "            value='100'\n",
       "            max='100',\n",
       "            style='width: 50%'\n",
       "        >\n",
       "         100\n",
       "        </progress>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing: /SVIRO_valid_images.tfrecord\n"
     ]
    }
   ],
   "source": [
    "record_name = '/SVIRO_valid_images.tfrecord'\n",
    "record_path = output_tf_record_output_path + record_name \n",
    "\n",
    "write_tf_record(valid_files, record_path, max_files=int(len(valid_files)))\n",
    "# write_tf_record(valid_files, record_path, max_files=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "f6ZoBOab6vXq"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <progress\n",
       "            value='100'\n",
       "            max='100',\n",
       "            style='width: 50%'\n",
       "        >\n",
       "         100\n",
       "        </progress>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing: /SVIRO_short_test_images.tfrecord\n",
      "['3', '0', '0', '418', '639']\n",
      "['3', '534', '61', '841', '639']\n",
      "['3', '0', '0', '393', '639']\n",
      "['2', '587', '190', '891', '639']\n",
      "['3', '656', '223', '938', '639']\n",
      "['4', '572', '362', '696', '481']\n",
      "['3', '100', '267', '340', '639']\n",
      "['2', '102', '244', '401', '639']\n",
      "['2', '134', '229', '416', '601']\n",
      "['1', '564', '221', '931', '639']\n",
      "['1', '0', '219', '380', '639']\n",
      "['3', '113', '420', '301', '639']\n",
      "['1', '0', '338', '362', '639']\n",
      "['4', '389', '433', '565', '561']\n",
      "['4', '590', '411', '675', '470']\n",
      "['2', '123', '207', '400', '628']\n",
      "['3', '0', '81', '451', '639']\n",
      "['1', '581', '294', '959', '639']\n",
      "['3', '100', '251', '358', '639']\n",
      "['3', '535', '59', '959', '639']\n",
      "['2', '127', '205', '401', '620']\n",
      "['1', '66', '238', '394', '639']\n",
      "['2', '557', '196', '789', '562']\n"
     ]
    }
   ],
   "source": [
    "record_name = '/SVIRO_short_test_images.tfrecord'\n",
    "record_path = output_tf_record_output_path + record_name \n",
    "\n",
    "# write_tf_record(test_files, record_path, max_files=int(len(test_files)))\n",
    "write_tf_record(test_files, record_path, max_files=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir '/content/training/train'"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "generate_svirotfrecord.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/tfrecord.ipynb",
     "timestamp": 1623368714978
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
